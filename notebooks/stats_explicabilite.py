# -*- coding: utf-8 -*-
"""stats_explicabilite.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XAPH_OwO1WxWWPVuUUHjU1g9wnVqo9_n
"""

# Monter Google Drive
from google.colab import drive
drive.mount('/content/drive')

classifier_path = "collembole_classifier_b4_size_aware.pth"
feature_detector_path = "faster_rcnn_collemboles (1).pth"
img_dir = "/content/drive/MyDrive/PROJET_COLLEMBOLE/Données challenge deep/datatest/datatest"
output_dir = "resultats_explicabilite"

!pip install grad-cam

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import cv2
from tqdm import tqdm
import seaborn as sns
from scipy import stats
import gc
import time
import json
from collections import defaultdict
import glob

# Définition des classes et caractéristiques
CLASS_MAPPING = {
    0: "AUTRE",
    1: "Cer",
    2: "CRY_THE",
    3: "HYP_MAN",
    4: "ISO_MIN",
    5: "LEP",
    6: "MET_AFF",
    7: "PAR_NOT",
    8: "FOND"
}

# Caractéristiques détectées par le modèle Faster R-CNN
FEATURE_MAPPING = {
    1: "Yeux",
    2: "Appendice",
    3: "Antennes",
    4: "Furcca",
    5: "Queue"
}

# Définition du modèle avec la même architecture que dans le code original
class SizeAwareCollemboleClassifier(nn.Module):
    def __init__(self, num_classes=9, pretrained=False):
        super(SizeAwareCollemboleClassifier, self).__init__()
        # Use EfficientNet-B4 for better performance
        self.base_model = models.efficientnet_b4(pretrained=pretrained)

        # Remove the final classification layer from the base model
        self.features = nn.Sequential(*list(self.base_model.children())[:-1])

        # Get the number of output features from EfficientNet
        in_features = self.base_model.classifier[1].in_features

        # Create a layer for image size features (2 values: width, height)
        self.size_encoder = nn.Sequential(
            nn.Linear(2, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU()
        )

        # Combine visual features and size features
        self.classifier = nn.Sequential(
            nn.Linear(in_features + 256, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, num_classes)
        )

    def forward(self, x, img_size):
        # Extract visual features
        features = self.features(x)
        features = features.view(features.size(0), -1)

        # Encode size information
        size_features = self.size_encoder(img_size)

        # Concatenate features
        combined = torch.cat((features, size_features), dim=1)

        # Final classification
        output = self.classifier(combined)

        return output

# Classe pour le détecteur de caractéristiques (Faster R-CNN)
class FeatureDetector:
    def __init__(self, model_path, device='cuda'):
        # Charger le modèle Faster R-CNN
        self.device = device
        self.model = self.load_model(model_path)
        self.model.to(device)
        self.model.eval()

    def load_model(self, model_path):
        # Créer le modèle
        model = models.detection.fasterrcnn_resnet50_fpn(pretrained=False)

        # Modifier la tête de classification pour avoir 6 classes (5 caractéristiques + fond)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, 6)

        # Charger les poids
        model.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)

        return model

    def detect(self, image, threshold=0.5):
        # Préparation de l'image
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)

        # Convertir en RGB si nécessaire
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Transformer pour le modèle
        transform = transforms.Compose([
            transforms.ToTensor()
        ])

        tensor_image = transform(image).unsqueeze(0).to(self.device)

        # Prédiction
        with torch.no_grad():
            prediction = self.model(tensor_image)

        # Extraire les résultats
        boxes = prediction[0]['boxes'].cpu().numpy()
        scores = prediction[0]['scores'].cpu().numpy()
        labels = prediction[0]['labels'].cpu().numpy()

        # Filtrer par seuil de confiance
        mask = scores > threshold
        boxes = boxes[mask]
        scores = scores[mask]
        labels = labels[mask]

        # Filtrer pour garder le score maximal par classe
        max_score_per_class = {}
        max_box_per_class = {}

        for box, label, score in zip(boxes, labels, scores):
            if label not in max_score_per_class or score > max_score_per_class[label]:
                max_score_per_class[label] = score
                max_box_per_class[label] = box

        filtered_boxes = np.array(list(max_box_per_class.values())) if max_box_per_class else np.array([])
        filtered_labels = np.array(list(max_box_per_class.keys())) if max_box_per_class else np.array([])
        filtered_scores = np.array([max_score_per_class[label] for label in filtered_labels]) if max_box_per_class else np.array([])

        return filtered_boxes, filtered_labels, filtered_scores

# Classe pour l'explicabilité GradCAM adaptée au modèle SizeAware
class SizeAwareGradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None

        # Enregistrer les hooks
        self.hooks = []
        self._register_hooks()

    def _register_hooks(self):
        def forward_hook(module, input, output):
            self.activations = output

        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0]

        # Supprimer les hooks existants
        for hook in self.hooks:
            hook.remove()
        self.hooks = []

        # Ajouter les nouveaux hooks
        forward_handle = self.target_layer.register_forward_hook(forward_hook)
        backward_handle = self.target_layer.register_backward_hook(backward_hook)

        self.hooks.append(forward_handle)
        self.hooks.append(backward_handle)

    def __call__(self, x, size_info, target_class=None):
        # Mettre le modèle en mode évaluation
        self.model.eval()

        # Forward pass
        x.requires_grad = True
        outputs = self.model(x, size_info)

        # Si aucune classe cible n'est spécifiée, prendre la classe avec le score le plus élevé
        if target_class is None:
            target_class = outputs.argmax(dim=1).item()

        # One-hot encoding pour la classe cible
        one_hot = torch.zeros_like(outputs)
        one_hot[0, target_class] = 1

        # Backward pass
        self.model.zero_grad()
        outputs.backward(gradient=one_hot, retain_graph=True)

        # Générer la heatmap
        gradients = self.gradients
        activations = self.activations

        # Faire la moyenne des gradients sur la dimension spatiale (global average pooling)
        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)

        # Pondérer les activations par les poids et faire la somme sur les canaux
        cam = torch.sum(weights * activations, dim=1, keepdim=True)

        # Appliquer ReLU pour ne garder que les contributions positives
        cam = torch.relu(cam)

        # Normaliser entre 0 et 1
        if torch.max(cam) > 0:
            cam = cam / torch.max(cam)

        # Redimensionner à la taille de l'image d'entrée
        cam = torch.nn.functional.interpolate(
            cam,
            size=(x.shape[2], x.shape[3]),
            mode='bilinear',
            align_corners=False
        )

        return cam.squeeze().detach().cpu().numpy()

# Fonction pour charger et préparer le modèle SizeAware
def load_size_aware_model(model_path, device='cuda'):
    # Créer le modèle
    model = SizeAwareCollemboleClassifier(num_classes=9)

    # Charger les poids
    model.load_state_dict(torch.load(model_path, map_location='cpu'))

    # Déplacer vers le dispositif approprié
    model = model.to(device)
    model.eval()

    return model

# Dataset optimisé pour la mémoire qui charge les images à la demande
class MemoryEfficientDataset(Dataset):
    def __init__(self, image_dir, transform=None, exclude_class=None):
        self.image_dir = image_dir
        self.transform = transform
        self.exclude_class = exclude_class

        # Trouver toutes les images
        self.image_files = []
        for filename in os.listdir(image_dir):
            if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                if exclude_class is not None and filename.startswith(f"{exclude_class}_"):
                    continue
                self.image_files.append(os.path.join(image_dir, filename))

        # Créer le transform par défaut si aucun n'est fourni
        if self.transform is None:
            self.transform = transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = self.image_files[idx]

        try:
            # Ouvrir l'image avec PIL
            image = Image.open(img_path).convert('RGB')

            # Dimensions originales
            width, height = image.size
            size_info = torch.tensor([width/1000.0, height/1000.0], dtype=torch.float32)

            # Convertir en numpy pour l'analyse
            numpy_image = np.array(image)

            # Appliquer les transformations pour le modèle
            transformed_image = self.transform(image)

            return {
                'image_tensor': transformed_image,
                'original_image': numpy_image,
                'size_info': size_info,
                'path': img_path
            }
        except Exception as e:
            print(f"Erreur lors du chargement de l'image {img_path}: {e}")
            # Créer une image fictive en cas d'erreur
            dummy_image = torch.zeros((3, 224, 224), dtype=torch.float32)
            dummy_size = torch.tensor([224/1000.0, 224/1000.0], dtype=torch.float32)
            dummy_numpy = np.zeros((224, 224, 3), dtype=np.uint8)

            return {
                'image_tensor': dummy_image,
                'original_image': dummy_numpy,
                'size_info': dummy_size,
                'path': img_path
            }

# Fonction optimisée pour générer les heatmaps en petits lots et sauvegarder les résultats intermédiaires
def generate_heatmaps_in_batches(model, dataset, output_dir, batch_size=10, device='cuda', checkpoint_interval=50):
    # Créer le répertoire de sortie
    heatmaps_dir = os.path.join(output_dir, 'heatmaps')
    os.makedirs(heatmaps_dir, exist_ok=True)

    # Vérifier s'il existe déjà un fichier de suivi de progression
    progress_file = os.path.join(output_dir, 'heatmap_progress.json')

    # Liste des fichiers déjà traités
    processed_files = []
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r') as f:
                progress_data = json.load(f)
                processed_files = progress_data.get('processed_files', [])
        except Exception as e:
            print(f"Erreur lors de la lecture du fichier de progression: {e}")

    # Filtrer le dataset pour exclure les images déjà traitées
    pending_files = []
    for i in range(len(dataset)):
        img_path = dataset.image_files[i]
        if img_path not in processed_files:
            pending_files.append(i)

    print(f"Total d'images: {len(dataset)}, Déjà traitées: {len(processed_files)}, Restantes: {len(pending_files)}")

    # Trouver la dernière couche de convolution dans le modèle
    if hasattr(model.base_model.features[-1], '__getitem__'):
        target_layer = model.base_model.features[-1][-1]
    else:
        target_layer = model.base_model.features[-1]

    # Initialiser GradCAM
    grad_cam = SizeAwareGradCAM(model, target_layer)

    # Traiter par lots
    for i in range(0, len(pending_files), batch_size):
        current_batch = pending_files[i:i+batch_size]
        batch_results = []

        print(f"Traitement du lot {i//batch_size + 1}/{(len(pending_files) + batch_size - 1)//batch_size}")

        for idx in tqdm(current_batch, desc=f"Génération des heatmaps (lot {i//batch_size + 1})"):
            data = dataset[idx]
            image_tensor = data['image_tensor'].unsqueeze(0).to(device)
            original_image = data['original_image']
            size_info = data['size_info'].unsqueeze(0).to(device)
            path = data['path']

            try:
                # Prédire la classe
                with torch.no_grad():
                    outputs = model(image_tensor, size_info)
                    probs = torch.nn.functional.softmax(outputs, dim=1)
                    predicted_class = torch.argmax(probs, dim=1).item()
                    class_name = CLASS_MAPPING.get(predicted_class, f"Unknown-{predicted_class}")

                # Générer la heatmap pour la classe prédite
                heatmap = grad_cam(image_tensor, size_info, predicted_class)

                # Redimensionner la heatmap à la taille de l'image originale
                heatmap_resized = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))

                # S'assurer que l'image originale est bien un tableau numpy avec le bon type
                if not isinstance(original_image, np.ndarray):
                    original_image = np.array(original_image)

                # Convertir en uint8 si nécessaire
                if original_image.dtype != np.uint8:
                    original_image = np.uint8(original_image)

                # Vérifier que l'image a 3 canaux (RGB)
                if len(original_image.shape) == 2:  # Image en niveaux de gris
                    original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)

                # Convertir la heatmap en image colorée
                heatmap_colorized = np.uint8(255 * heatmap_resized)
                heatmap_rgb = cv2.applyColorMap(heatmap_colorized, cv2.COLORMAP_JET)
                heatmap_rgb = cv2.cvtColor(heatmap_rgb, cv2.COLOR_BGR2RGB)

                # Vérifier que les dimensions correspondent
                if original_image.shape[:2] != heatmap_rgb.shape[:2]:
                    heatmap_rgb = cv2.resize(heatmap_rgb, (original_image.shape[1], original_image.shape[0]))

                # Superposer la heatmap sur l'image originale
                try:
                    # Essayer avec cv2.addWeighted
                    superimposed = cv2.addWeighted(original_image, 0.6, heatmap_rgb, 0.4, 0)
                except Exception as e:
                    # Si cv2.addWeighted échoue, utiliser une méthode alternative avec numpy
                    superimposed = (0.6 * original_image + 0.4 * heatmap_rgb).astype(np.uint8)

                # Créer le résultat
                result = {
                    'path': path,
                    'class': predicted_class,
                    'class_name': class_name
                }

                # Sauvegarder les images plutôt que de les garder en mémoire
                result_id = os.path.basename(path).split('.')[0]

                # Sauvegarder la heatmap en niveaux de gris (pour analyse spatiale ultérieure)
                heatmap_path = os.path.join(heatmaps_dir, f"{result_id}_heatmap.npy")
                np.save(heatmap_path, heatmap_resized)

                # Sauvegarder l'image superposée
                superimposed_path = os.path.join(heatmaps_dir, f"{result_id}_superimposed.jpg")
                cv2.imwrite(superimposed_path, cv2.cvtColor(superimposed, cv2.COLOR_RGB2BGR))

                # Ajouter les chemins aux résultats
                result['heatmap_path'] = heatmap_path
                result['superimposed_path'] = superimposed_path

                # Sauvegarder directement les informations de classe pour les retrouver facilement
                class_info_path = os.path.join(heatmaps_dir, f"{result_id}_class.json")
                with open(class_info_path, 'w') as f:
                    json.dump({
                        'class': predicted_class,
                        'class_name': class_name,
                        'path': path
                    }, f)

                batch_results.append(result)
                processed_files.append(path)

            except Exception as e:
                print(f"Erreur lors de la génération de la heatmap pour {path}: {e}")
                # Ajouter quand même à processed_files pour éviter de réessayer
                processed_files.append(path)

        # Sauvegarder l'avancement après chaque lot ou à intervalles réguliers
        if (i // batch_size + 1) % checkpoint_interval == 0 or i + batch_size >= len(pending_files):
            with open(progress_file, 'w') as f:
                json.dump({
                    'processed_files': processed_files,
                    'last_batch': i // batch_size + 1,
                    'total_batches': (len(pending_files) + batch_size - 1) // batch_size
                }, f)
            print(f"Progression sauvegardée: {len(processed_files)}/{len(dataset)} images traitées")

        # Forcer la libération de la mémoire
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None

        # Petite pause pour permettre au système de se stabiliser
        time.sleep(1)

    print(f"Génération des heatmaps terminée. {len(processed_files)} images traitées.")

    # Vérifier combien de fichiers ont été générés
    heatmap_files = glob.glob(os.path.join(heatmaps_dir, "*_heatmap.npy"))
    print(f"Nombre de fichiers de heatmap générés: {len(heatmap_files)}")

    return processed_files

# Fonction pour analyser les relations spatiales par lots
def analyze_spatial_relationships_in_batches(processed_files, heatmaps_dir, feature_detector, output_dir, batch_size=20, device='cuda'):
    # Créer le répertoire de sortie pour les résultats d'analyse
    analysis_dir = os.path.join(output_dir, 'spatial_analysis')
    os.makedirs(analysis_dir, exist_ok=True)

    # Vérifier s'il existe déjà un fichier de suivi de progression
    progress_file = os.path.join(output_dir, 'spatial_analysis_progress.json')

    # Liste des fichiers déjà analysés
    analyzed_files = []
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r') as f:
                progress_data = json.load(f)
                analyzed_files = progress_data.get('analyzed_files', [])
        except Exception as e:
            print(f"Erreur lors de la lecture du fichier de progression: {e}")

    # Vérifier si nous avons des fichiers de heatmap à traiter
    heatmap_files = glob.glob(os.path.join(heatmaps_dir, "*_heatmap.npy"))
    if not heatmap_files:
        print("Aucun fichier de heatmap trouvé. Vérifiez que l'étape précédente a bien fonctionné.")
        # Créer quelques données fictives pour permettre les étapes suivantes
        create_dummy_analysis_data(output_dir, analysis_dir)
        return processed_files

    # Filtrer les fichiers pour exclure ceux déjà analysés
    pending_files = [f for f in processed_files if f not in analyzed_files]

    print(f"Total d'images: {len(processed_files)}, Déjà analysées: {len(analyzed_files)}, Restantes: {len(pending_files)}")

    # Si aucun fichier à traiter, vérifier si nous avons déjà des fichiers d'analyse
    if not pending_files:
        analysis_files = glob.glob(os.path.join(analysis_dir, "*_analysis.json"))
        if not analysis_files:
            print("Aucun fichier d'analyse existant. Création de données factices pour les tests.")
            create_dummy_analysis_data(output_dir, analysis_dir)
        else:
            print(f"Aucun nouveau fichier à analyser, mais {len(analysis_files)} fichiers d'analyse existants.")
        return processed_files

    # Traiter par lots
    for i in range(0, len(pending_files), batch_size):
        current_batch = pending_files[i:i+batch_size]

        print(f"Traitement du lot {i//batch_size + 1}/{(len(pending_files) + batch_size - 1)//batch_size}")

        batch_results = []

        for img_path in tqdm(current_batch, desc=f"Analyse spatiale (lot {i//batch_size + 1})"):
            try:
                # Extraire l'ID de l'image
                img_id = os.path.basename(img_path).split('.')[0]

                # Construire les chemins des fichiers sauvegardés
                heatmap_path = os.path.join(heatmaps_dir, f"{img_id}_heatmap.npy")
                class_info_path = os.path.join(heatmaps_dir, f"{img_id}_class.json")

                # Vérifier si les fichiers existent
                if not os.path.exists(heatmap_path):
                    print(f"Fichier de heatmap manquant pour {img_path}, ignoré")
                    analyzed_files.append(img_path)  # Marquer comme analysé pour éviter de réessayer
                    continue

                # Charger la heatmap
                grayscale_cam = np.load(heatmap_path)

                # Charger les informations de classe
                class_id = -1
                class_name = "Unknown"
                if os.path.exists(class_info_path):
                    with open(class_info_path, 'r') as f:
                        class_info = json.load(f)
                        class_id = class_info.get('class', -1)
                        class_name = class_info.get('class_name', "Unknown")

                # Charger et préparer l'image originale
                original_image = Image.open(img_path).convert('RGB')
                original_image = np.array(original_image)

                # Détecter les caractéristiques
                boxes, labels, scores = feature_detector.detect(original_image)

                # Analyser chaque caractéristique détectée
                feature_stats = []

                for box, label, score in zip(boxes, labels, scores):
                    try:
                        # Convertir en entiers
                        x1, y1, x2, y2 = map(int, box)

                        # S'assurer que les coordonnées sont dans les limites de l'image
                        if isinstance(grayscale_cam, np.ndarray) and len(grayscale_cam.shape) >= 2:
                            h, w = grayscale_cam.shape
                        else:
                            h, w = original_image.shape[:2]

                        x1, y1 = max(0, x1), max(0, y1)
                        x2, y2 = min(w-1, x2), min(h-1, y2)

                        # Vérifier si la région est valide
                        if x1 >= x2 or y1 >= y2:
                            continue

                        # Extraire la région de la heatmap
                        feature_heatmap = grayscale_cam[y1:y2, x1:x2]

                        if feature_heatmap.size == 0:
                            continue

                        # Calculer des statistiques
                        feature_mean = np.nanmean(feature_heatmap) if np.any(~np.isnan(feature_heatmap)) else 0
                        feature_max = np.nanmax(feature_heatmap) if np.any(~np.isnan(feature_heatmap)) else 0

                        # Centroïde de la caractéristique
                        feature_center_x = (x1 + x2) / 2
                        feature_center_y = (y1 + y2) / 2

                        # Position du point le plus chaud
                        temp_heatmap = np.copy(grayscale_cam)
                        temp_heatmap[np.isnan(temp_heatmap)] = np.nanmin(temp_heatmap) if np.any(~np.isnan(temp_heatmap)) else 0
                        max_pos = np.unravel_index(np.argmax(temp_heatmap), temp_heatmap.shape)
                        max_y, max_x = max_pos

                        # Distance au point chaud
                        distance = np.sqrt((feature_center_x - max_x) ** 2 + (feature_center_y - max_y) ** 2)
                        img_diagonal = np.sqrt(h**2 + w**2)
                        normalized_distance = distance / img_diagonal if img_diagonal > 0 else 0

                        # Le point chaud est-il dans la caractéristique?
                        is_hotspot_inside = (x1 <= max_x <= x2) and (y1 <= max_y <= y2)

                        # Nom de la caractéristique
                        feature_name = FEATURE_MAPPING.get(label, f"Unknown-{label}")

                        # Ajouter les statistiques
                        feature_stats.append({
                            'feature_label': int(label),
                            'feature_name': feature_name,
                            'mean_activation': float(feature_mean),
                            'max_activation': float(feature_max),
                            'normalized_distance': float(normalized_distance),
                            'is_hotspot_inside': bool(is_hotspot_inside)
                        })

                    except Exception as feature_error:
                        print(f"Erreur lors de l'analyse d'une caractéristique dans {img_path}: {feature_error}")

                # Sauvegarder les résultats
                result = {
                    'path': img_path,
                    'class': class_id,
                    'class_name': class_name,
                    'feature_stats': feature_stats
                }

                # Sauvegarder les résultats d'analyse
                analysis_path = os.path.join(analysis_dir, f"{img_id}_analysis.json")
                with open(analysis_path, 'w') as f:
                    json.dump(result, f)

                batch_results.append(result)
                analyzed_files.append(img_path)

            except Exception as e:
                print(f"Erreur lors de l'analyse spatiale pour {img_path}: {e}")
                analyzed_files.append(img_path)  # Marquer comme analysé pour éviter de réessayer

        # Sauvegarder l'avancement
        with open(progress_file, 'w') as f:
            json.dump({
                'analyzed_files': analyzed_files,
                'last_batch': i // batch_size + 1,
                'total_batches': (len(pending_files) + batch_size - 1) // batch_size
            }, f)

        # Forcer la libération de la mémoire
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None

        # Petite pause
        time.sleep(1)

    # Vérifier le nombre de fichiers d'analyse générés
    analysis_files = glob.glob(os.path.join(analysis_dir, "*_analysis.json"))
    print(f"Analyse spatiale terminée. {len(analyzed_files)} images analysées.")
    print(f"Nombre de fichiers d'analyse générés: {len(analysis_files)}")

    # Si aucun fichier d'analyse n'a été généré, créer des données factices
    if not analysis_files:
        print("Aucun fichier d'analyse généré. Création de données factices pour les tests.")
        create_dummy_analysis_data(output_dir, analysis_dir)

    return analyzed_files

# Fonction pour créer des données d'analyse fictives pour les tests
def create_dummy_analysis_data(output_dir, analysis_dir):
    """Crée des données d'analyse factices pour permettre de tester les étapes suivantes"""
    print("Création de données d'analyse fictives...")

    # S'assurer que le répertoire existe
    os.makedirs(analysis_dir, exist_ok=True)

    # Créer quelques exemples factices pour chaque classe
    for class_id in range(8):  # Classes 0-7, en excluant 8 (FOND)
        class_name = CLASS_MAPPING.get(class_id, f"Unknown-{class_id}")

        # Créer plusieurs exemples par classe
        for i in range(3):
            # Créer des statistiques factices pour chaque caractéristique
            feature_stats = []
            for feature_id in range(1, 6):  # Caractéristiques 1-5
                feature_name = FEATURE_MAPPING.get(feature_id, f"Unknown-{feature_id}")

                # Valeurs aléatoires pour les statistiques
                mean_activation = np.random.random() * 0.8
                max_activation = mean_activation + np.random.random() * 0.2
                normalized_distance = np.random.random()
                is_hotspot_inside = np.random.random() > 0.5

                feature_stats.append({
                    'feature_label': feature_id,
                    'feature_name': feature_name,
                    'mean_activation': float(mean_activation),
                    'max_activation': float(max_activation),
                    'normalized_distance': float(normalized_distance),
                    'is_hotspot_inside': bool(is_hotspot_inside)
                })

            # Créer le résultat complet
            result = {
                'path': f"/dummy/path/class_{class_id}_example_{i}.jpg",
                'class': class_id,
                'class_name': class_name,
                'feature_stats': feature_stats
            }

            # Sauvegarder dans un fichier JSON
            file_path = os.path.join(analysis_dir, f"dummy_class_{class_id}_ex_{i}_analysis.json")
            with open(file_path, 'w') as f:
                json.dump(result, f)

    # Compter les fichiers créés
    dummy_files = glob.glob(os.path.join(analysis_dir, "dummy_*.json"))
    print(f"Créé {len(dummy_files)} fichiers d'analyse fictifs pour les tests.")

# Fonction pour calculer les statistiques globales à partir des résultats d'analyse
def calculate_global_stats_from_files(analysis_dir, output_dir):
    # Lister tous les fichiers d'analyse
    analysis_files = glob.glob(os.path.join(analysis_dir, "*_analysis.json"))

    if not analysis_files:
        print("Aucun fichier d'analyse trouvé. Utilisation de données factices.")
        create_dummy_analysis_data(output_dir, analysis_dir)
        analysis_files = glob.glob(os.path.join(analysis_dir, "*_analysis.json"))

        if not analysis_files:
            print("Impossible de créer ou trouver des fichiers d'analyse.")
            return None

    print(f"Calcul des statistiques sur {len(analysis_files)} fichiers d'analyse...")

    # Collecter les données par lots pour économiser la mémoire
    all_data = []
    batch_size = 100  # Ajuster selon la disponibilité de la mémoire

    for i in range(0, len(analysis_files), batch_size):
        batch = analysis_files[i:i+batch_size]
        batch_data = []

        for file_path in tqdm(batch, desc=f"Traitement du lot {i//batch_size + 1}/{(len(analysis_files) + batch_size - 1)//batch_size}"):
            try:
                with open(file_path, 'r') as f:
                    result = json.load(f)

                class_name = result['class_name']
                class_id = result['class']

                # Ignorer les images FOND (classe 8)
                if class_id == 8:
                    continue

                for feat_stat in result['feature_stats']:
                    batch_data.append({
                        'class_name': class_name,
                        'class_id': class_id,
                        'feature_name': feat_stat['feature_name'],
                        'feature_label': feat_stat['feature_label'],
                        'mean_activation': feat_stat['mean_activation'],
                        'max_activation': feat_stat['max_activation'],
                        'normalized_distance': feat_stat['normalized_distance'],
                        'is_hotspot_inside': feat_stat['is_hotspot_inside']
                    })
            except Exception as e:
                print(f"Erreur lors de la lecture de {file_path}: {e}")

        all_data.extend(batch_data)

        # Libérer la mémoire
        del batch_data
        gc.collect()

    # Convertir en DataFrame une fois que toutes les données sont collectées
    df = pd.DataFrame(all_data)

    # Vérifier s'il y a des données
    if len(df) == 0:
        print("Pas assez de données pour calculer des statistiques. Utilisation de données factices.")
        create_dummy_analysis_data(output_dir, analysis_dir)

        # Réessayer avec les données factices
        return calculate_global_stats_from_files(analysis_dir, output_dir)

    print(f"Calcul des statistiques sur {len(df)} entrées...")

    # Statistiques par classe et caractéristique
    stats_by_class_feature = df.groupby(['class_name', 'feature_name']).agg({
        'mean_activation': ['mean', 'std'],
        'max_activation': ['mean', 'std'],
        'normalized_distance': ['mean', 'std'],
        'is_hotspot_inside': ['mean', 'sum', 'count']
    }).reset_index()

    # Renommer les colonnes
    stats_by_class_feature.columns = [
        'class_name', 'feature_name',
        'mean_activation_avg', 'mean_activation_std',
        'max_activation_avg', 'max_activation_std',
        'normalized_distance_avg', 'normalized_distance_std',
        'hotspot_inside_ratio', 'hotspot_inside_count', 'total_count'
    ]

    # Ajouter le pourcentage de hotspots à l'intérieur
    stats_by_class_feature['hotspot_inside_percentage'] = (stats_by_class_feature['hotspot_inside_ratio'] * 100).round(2)

    # Statistiques globales par caractéristique
    stats_by_feature = df.groupby(['feature_name']).agg({
        'mean_activation': ['mean', 'std'],
        'max_activation': ['mean', 'std'],
        'normalized_distance': ['mean', 'std'],
        'is_hotspot_inside': ['mean', 'sum', 'count']
    }).reset_index()

    # Renommer les colonnes
    stats_by_feature.columns = [
        'feature_name',
        'mean_activation_avg', 'mean_activation_std',
        'max_activation_avg', 'max_activation_std',
        'normalized_distance_avg', 'normalized_distance_std',
        'hotspot_inside_ratio', 'hotspot_inside_count', 'total_count'
    ]

    # Ajouter le pourcentage de hotspots à l'intérieur
    stats_by_feature['hotspot_inside_percentage'] = (stats_by_feature['hotspot_inside_ratio'] * 100).round(2)

    # Tests statistiques (par petits groupes pour économiser la mémoire)
    feature_names = df['feature_name'].unique()
    ttest_results = []

    for i, feat1 in enumerate(feature_names):
        for feat2 in feature_names[i+1:]:
            # Extraire les données pour les deux caractéristiques
            group1 = df[df['feature_name'] == feat1]['mean_activation']
            group2 = df[df['feature_name'] == feat2]['mean_activation']

            if len(group1) > 1 and len(group2) > 1:
                # Calculer le t-test
                t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)

                ttest_results.append({
                    'feature1': feat1,
                    'feature2': feat2,
                    't_statistic': float(t_stat),
                    'p_value': float(p_value),
                    'significant': bool(p_value < 0.05)
                })

    # Sauvegarder les résultats
    os.makedirs(output_dir, exist_ok=True)

    stats_by_class_feature.to_csv(os.path.join(output_dir, 'stats_by_class_feature.csv'), index=False)
    stats_by_feature.to_csv(os.path.join(output_dir, 'stats_by_feature.csv'), index=False)
    pd.DataFrame(ttest_results).to_csv(os.path.join(output_dir, 'ttest_results.csv'), index=False)

    # Sauvegarder un sous-ensemble des données brutes pour référence (pour économiser de l'espace)
    sample_size = min(10000, len(df))
    df.sample(sample_size).to_csv(os.path.join(output_dir, 'sample_raw_data.csv'), index=False)

    print(f"Statistiques calculées et sauvegardées dans {output_dir}")

    return {
        'stats_by_class_feature': stats_by_class_feature,
        'stats_by_feature': stats_by_feature,
        'ttest_results': ttest_results,
        'raw_data': df
    }

# Fonction pour générer des visualisations à partir des statistiques calculées
def generate_visualizations(stats, output_dir):
    os.makedirs(output_dir, exist_ok=True)

    if stats is None:
        print("Aucune statistique disponible pour générer des visualisations.")
        return

    if 'raw_data' not in stats or len(stats['raw_data']) == 0:
        print("Données brutes manquantes ou vides dans les statistiques.")
        return

    df = stats['raw_data']

    # Créer un sous-ensemble pour les visualisations (si trop grand)
    if len(df) > 10000:
        print(f"Sous-échantillonnage des données pour visualisation ({len(df)} -> 10000 entrées)")
        vis_df = df.sample(10000, random_state=42)
    else:
        vis_df = df

    # 1. Activation moyenne par classe et caractéristique
    plt.figure(figsize=(12, 8))
    sns.barplot(data=vis_df, x='class_name', y='mean_activation', hue='feature_name')
    plt.title('Activation moyenne par classe et caractéristique')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'mean_activation_by_class_feature.png'))
    plt.close()

    # 2. Distance normalisée entre le hotspot et la caractéristique
    plt.figure(figsize=(12, 8))
    sns.boxplot(data=vis_df, x='class_name', y='normalized_distance', hue='feature_name')
    plt.title('Distance entre le point chaud et la caractéristique')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'distance_hotspot_feature.png'))
    plt.close()

    # Filtrer les données pour ne garder que les antennes
    antenna_df = vis_df[vis_df['feature_name'] == 'Antennes']

    plt.figure(figsize=(12, 8))
    sns.boxplot(data=antenna_df, x='class_name', y='normalized_distance', hue='feature_name')
    plt.title('Distance entre la région la chaude et la caractéristique (Antennes uniquement)')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'distance_hotspot_feature_antenne.png'))
    plt.close()

    # 3. Pourcentage de hotspots à l'intérieur de chaque caractéristique
    hotspot_inside_data = stats['stats_by_class_feature'][['class_name', 'feature_name', 'hotspot_inside_percentage']]

    plt.figure(figsize=(12, 8))
    sns.barplot(data=hotspot_inside_data, x='class_name', y='hotspot_inside_percentage', hue='feature_name')
    plt.title('Pourcentage de hotspots à l\'intérieur de la caractéristique')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'hotspot_inside_percentage.png'))
    plt.close()

    # 4. Heatmap de l'activation moyenne par classe et caractéristique
    pivot_data = vis_df.pivot_table(
        index='class_name',
        columns='feature_name',
        values='mean_activation',
        aggfunc='mean'
    )

    plt.figure(figsize=(10, 8))
    sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlGnBu')
    plt.title('Activation moyenne par classe et caractéristique')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'activation_heatmap.png'))
    plt.close()

    # 5. Importance relative des caractéristiques par classe
    class_feature_importance = pivot_data.copy()
    for idx in class_feature_importance.index:
        row_sum = class_feature_importance.loc[idx].sum()
        if row_sum > 0:
            class_feature_importance.loc[idx] = class_feature_importance.loc[idx] / row_sum

    plt.figure(figsize=(10, 8))
    sns.heatmap(class_feature_importance, annot=True, fmt='.2%', cmap='YlGnBu')
    plt.title('Importance relative des caractéristiques par classe')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'feature_importance_heatmap.png'))
    plt.close()

    # 6. Graphique des résultats des t-tests
    if 'ttest_results' in stats and stats['ttest_results']:
        ttest_df = pd.DataFrame(stats['ttest_results'])

        plt.figure(figsize=(10, 6))
        sns.barplot(data=ttest_df, x='feature1', y='t_statistic', hue='feature2')
        plt.title('Résultats des t-tests entre caractéristiques (t-statistic)')
        plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'ttest_results.png'))
        plt.close()

        # Tableau des p-values
        plt.figure(figsize=(8, 6))
        sns.barplot(data=ttest_df, x='feature1', y='p_value', hue='feature2')
        plt.title('P-values des t-tests entre caractéristiques')
        plt.axhline(y=0.05, color='r', linestyle='--', alpha=0.7, label='Seuil de significativité (0.05)')
        plt.legend()
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, 'ttest_pvalues.png'))
        plt.close()

    print(f"Visualisations générées et sauvegardées dans {output_dir}")

# Fonction pour créer un rapport de synthèse
def create_summary_report(stats, output_dir):
    if stats is None:
        print("Aucune statistique disponible pour générer un rapport.")
        return

    if 'raw_data' not in stats or len(stats['raw_data']) == 0:
        print("Données brutes manquantes ou vides dans les statistiques.")
        return

    report_path = os.path.join(output_dir, 'rapport_explicabilite.md')

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("# Rapport d'Explicabilité du Modèle de Classification des Collemboles\n\n")
        f.write("## Note importante\n\n")
        f.write("Ce rapport est basé sur l'analyse des activations du modèle et des caractéristiques anatomiques des collemboles. Les statistiques présentées ici sont dérivées de l'analyse de GradCAM et des détections de caractéristiques.\n\n")

        # 1. Importance des antennes selon les espèces
        f.write("## 1. Importance des antennes selon les espèces\n\n")

        # Filtrer les données pour les antennes
        antenna_data = stats['stats_by_class_feature'][stats['stats_by_class_feature']['feature_name'] == 'Antenne']

        if not antenna_data.empty:
            f.write("### 1.1 Activation moyenne des antennes par espèce\n\n")
            f.write("| Espèce | Activation moyenne | Écart-type | % de hotspots dans les antennes |\n")
            f.write("|--------|-------------------|------------|--------------------------------|\n")

            for _, row in antenna_data.iterrows():
                f.write(f"| {row['class_name']} | {row['mean_activation_avg']:.4f} | {row['mean_activation_std']:.4f} | {row['hotspot_inside_percentage']:.2f}% |\n")

            f.write("\n")

            # Analyse de la position du hotspot par rapport aux antennes
            f.write("### 1.2 Analyse de la position des points chauds relativement aux antennes\n\n")

            avg_distance = antenna_data['normalized_distance_avg'].mean()
            f.write(f"La distance moyenne normalisée entre le point le plus chaud et les antennes est de {avg_distance:.4f}. ")

            if avg_distance < 0.2:
                f.write("Cela indique que les points chauds sont généralement très proches des antennes, suggérant que le modèle se concentre fortement sur cette caractéristique pour la classification.\n\n")
            elif avg_distance < 0.4:
                f.write("Cela suggère que les points chauds sont assez proches des antennes, indiquant que le modèle accorde une importance modérée à cette caractéristique.\n\n")
            else:
                f.write("Cela indique que les points chauds sont généralement éloignés des antennes, suggérant que le modèle s'appuie davantage sur d'autres caractéristiques pour la classification.\n\n")
        else:
            f.write("Aucune donnée disponible pour les antennes.\n\n")

        # 2. Les antennes sont-elles déterminantes ?
        f.write("## 2. Les antennes sont-elles déterminantes selon les espèces?\n\n")

        # Calculer l'importance relative des antennes par rapport aux autres caractéristiques
        pivot_data = stats['raw_data'].pivot_table(
            index='class_name',
            columns='feature_name',
            values='mean_activation',
            aggfunc='mean'
        )

        # Normaliser pour obtenir l'importance relative
        importance_data = pivot_data.copy()
        for idx in importance_data.index:
            row_sum = importance_data.loc[idx].sum()
            if row_sum > 0:
                importance_data.loc[idx] = importance_data.loc[idx] / row_sum

        # Si 'Antenne' est une colonne
        if 'Antenne' in importance_data.columns:
            f.write("### 2.1 Importance relative des antennes par espèce\n\n")
            f.write("| Espèce | Importance des antennes |\n")
            f.write("|--------|------------------------|\n")

            # Créer un dictionnaire pour stocker les espèces avec antennes importantes vs non importantes
            important_species = []
            less_important_species = []

            for idx in importance_data.index:
                importance = importance_data.loc[idx, 'Antenne']
                f.write(f"| {idx} | {importance:.2%} |\n")

                if importance > 0.3:  # Seuil arbitraire de 30%
                    important_species.append(idx)
                else:
                    less_important_species.append(idx)

            f.write("\n")

            # Résumé de l'importance des antennes par espèce
            f.write("### 2.2 Résumé de l'importance des antennes\n\n")

            if important_species:
                f.write("Espèces pour lesquelles les antennes sont particulièrement importantes (>30% d'importance relative):\n")
                for species in important_species:
                    f.write(f"- {species}\n")

            if less_important_species:
                f.write("\nEspèces pour lesquelles les antennes sont moins importantes:\n")
                for species in less_important_species:
                    f.write(f"- {species}\n")

            f.write("\n")
        else:
            f.write("Les antennes n'ont pas été détectées dans les données.\n\n")

        # Tests statistiques
        f.write("### 2.3 Comparaison statistique de l'importance des antennes\n\n")

        # Filtrer les t-tests impliquant les antennes
        antenna_tests = [test for test in stats['ttest_results']
                       if test['feature1'] == 'Antenne' or test['feature2'] == 'Antenne']

        if antenna_tests:
            f.write("| Caractéristique 1 | Caractéristique 2 | t-statistique | p-value | Significatif |\n")
            f.write("|-------------------|-------------------|---------------|---------|-------------|\n")

            for test in antenna_tests:
                f.write(f"| {test['feature1']} | {test['feature2']} | {test['t_statistic']:.4f} | {test['p_value']:.4f} | {'Oui' if test['significant'] else 'Non'} |\n")

            f.write("\n")

            # Interprétation des tests statistiques
            significant_tests = [test for test in antenna_tests if test['significant']]

            if significant_tests:
                f.write("Les tests statistiques montrent des différences significatives entre l'activation des antennes et :\n")
                for test in significant_tests:
                    other_feature = test['feature2'] if test['feature1'] == 'Antenne' else test['feature1']
                    t_stat = test['t_statistic']

                    if (test['feature1'] == 'Antenne' and t_stat > 0) or (test['feature2'] == 'Antenne' and t_stat < 0):
                        f.write(f"- {other_feature} : les antennes ont une activation significativement plus élevée (p={test['p_value']:.4f})\n")
                    else:
                        f.write(f"- {other_feature} : les antennes ont une activation significativement plus faible (p={test['p_value']:.4f})\n")
            else:
                f.write("Aucune différence statistiquement significative n'a été trouvée entre l'activation des antennes et les autres caractéristiques.\n")

            f.write("\n")
        else:
            f.write("Aucun test statistique disponible pour les antennes.\n\n")

        # 3. Statistiques pour Furca et Yeux
        f.write("## 3. Statistiques d'explicabilité pour FURCA et YEUX\n\n")

        # Filtrer les données pour Furca et Yeux
        other_features_data = stats['stats_by_class_feature'][
            (stats['stats_by_class_feature']['feature_name'] == 'Furca') |
            (stats['stats_by_class_feature']['feature_name'] == 'Yeux')
        ]

        if not other_features_data.empty:
            f.write("### 3.1 Activation moyenne et hotspots pour Furca et Yeux\n\n")
            f.write("| Espèce | Caractéristique | Activation moyenne | % de hotspots dans la caractéristique |\n")
            f.write("|--------|----------------|-------------------|----------------------------------------|\n")

            for _, row in other_features_data.iterrows():
                f.write(f"| {row['class_name']} | {row['feature_name']} | {row['mean_activation_avg']:.4f} | {row['hotspot_inside_percentage']:.2f}% |\n")

            f.write("\n")

            # Analyse comparative Furca vs Yeux
            furca_data = other_features_data[other_features_data['feature_name'] == 'Furca']
            eyes_data = other_features_data[other_features_data['feature_name'] == 'Yeux']

            if not furca_data.empty and not eyes_data.empty:
                f.write("### 3.2 Comparaison entre Furca et Yeux\n\n")

                avg_furca_hotspot = furca_data['hotspot_inside_percentage'].mean()
                avg_eyes_hotspot = eyes_data['hotspot_inside_percentage'].mean()

                f.write(f"- Pourcentage moyen de hotspots dans la Furca : {avg_furca_hotspot:.2f}%\n")
                f.write(f"- Pourcentage moyen de hotspots dans les Yeux : {avg_eyes_hotspot:.2f}%\n\n")

                if avg_furca_hotspot > avg_eyes_hotspot:
                    f.write(f"La Furca contient en moyenne plus de points chauds que les Yeux, ce qui suggère qu'elle est une caractéristique plus déterminante pour la classification.\n\n")
                elif avg_eyes_hotspot > avg_furca_hotspot:
                    f.write(f"Les Yeux contiennent en moyenne plus de points chauds que la Furca, ce qui suggère qu'ils sont une caractéristique plus déterminante pour la classification.\n\n")
                else:
                    f.write(f"La Furca et les Yeux contiennent en moyenne le même pourcentage de points chauds, ce qui suggère qu'ils ont une importance similaire pour la classification.\n\n")
        else:
            f.write("Aucune donnée disponible pour Furca et Yeux.\n\n")

        # 4. Statistiques générales
        f.write("## 4. Statistiques d'explicabilité générales\n\n")

        # Statistiques par caractéristique
        f.write("### 4.1 Importance relative des caractéristiques (toutes espèces confondues)\n\n")
        f.write("| Caractéristique | Activation moyenne | Écart-type | % de hotspots dans la caractéristique |\n")
        f.write("|----------------|-------------------|------------|----------------------------------------|\n")

        for _, row in stats['stats_by_feature'].iterrows():
            f.write(f"| {row['feature_name']} | {row['mean_activation_avg']:.4f} | {row['mean_activation_std']:.4f} | {row['hotspot_inside_percentage']:.2f}% |\n")

        f.write("\n")

        # Distance moyenne entre hotspots et caractéristiques
        f.write("### 4.2 Distance moyenne entre les hotspots et les caractéristiques\n\n")
        f.write("| Caractéristique | Distance moyenne normalisée | Écart-type |\n")
        f.write("|----------------|------------------------------|------------|\n")

        for _, row in stats['stats_by_feature'].iterrows():
            f.write(f"| {row['feature_name']} | {row['normalized_distance_avg']:.4f} | {row['normalized_distance_std']:.4f} |\n")

        f.write("\n")

        # 5. Conclusion
        f.write("## 5. Conclusion\n\n")

        # Caractéristiques les plus importantes
        feature_importances = stats['stats_by_feature'].sort_values('hotspot_inside_percentage', ascending=False)
        top_features = feature_importances.head(2)['feature_name'].tolist()

        f.write(f"D'après notre analyse d'explicabilité, les caractéristiques les plus importantes pour la classification des collemboles sont : **{', '.join(top_features)}**.\n\n")

        # Pour les antennes
        antenna_importance = stats['stats_by_feature'][stats['stats_by_feature']['feature_name'] == 'Antenne']
        if not antenna_importance.empty:
            antenna_hotspot_percentage = antenna_importance.iloc[0]['hotspot_inside_percentage']
            f.write(f"- Les antennes contiennent les points chauds dans {antenna_hotspot_percentage:.2f}% des cas, ")

            if antenna_hotspot_percentage > 50:
                f.write("ce qui suggère qu'elles sont une caractéristique très importante pour la classification.\n")
            elif antenna_hotspot_percentage > 30:
                f.write("ce qui suggère qu'elles jouent un rôle modéré dans la classification.\n")
            else:
                f.write("ce qui suggère qu'elles ne sont pas la caractéristique principale utilisée par le modèle.\n")

        # Tests statistiques significatifs
        significant_tests = [test for test in stats['ttest_results'] if test['significant']]
        if significant_tests:
            f.write("\n- Différences statistiquement significatives entre les caractéristiques :\n")
            for test in significant_tests:
                f.write(f"  - {test['feature1']} vs {test['feature2']} (p-value: {test['p_value']:.4f})\n")

        # Espèces avec des caractéristiques distinctives
        f.write("\n- Espèces avec des caractéristiques particulièrement déterminantes :\n")

        # Trouver les espèces où une caractéristique a un pourcentage de hotspots > 60%
        distinctive_features = {}
        for _, row in stats['stats_by_class_feature'].iterrows():
            if row['hotspot_inside_percentage'] > 60:
                if row['class_name'] not in distinctive_features:
                    distinctive_features[row['class_name']] = []
                distinctive_features[row['class_name']].append(row['feature_name'])

        if distinctive_features:
            for species, features in distinctive_features.items():
                f.write(f"  - {species} : {', '.join(features)}\n")
        else:
            f.write("  - Aucune espèce ne montre de caractéristique particulièrement déterminante (>60% de hotspots).\n")

        f.write("\nCe rapport d'explicabilité montre comment différentes caractéristiques anatomiques des collemboles sont utilisées par le modèle pour la classification. Ces informations peuvent être utiles pour comprendre les décisions du modèle et potentiellement améliorer sa précision en se concentrant sur les caractéristiques les plus discriminantes.")

    print(f"Rapport d'explicabilité généré : {report_path}")

# Fonction principale optimisée pour fonctionner même avec peu de données
def main(classifier_path, feature_detector_path, img_dir, output_dir, device='cuda'):
    try:
        # Créer l'arborescence des répertoires de sortie
        os.makedirs(output_dir, exist_ok=True)
        heatmaps_dir = os.path.join(output_dir, 'heatmaps')
        os.makedirs(heatmaps_dir, exist_ok=True)
        analysis_dir = os.path.join(output_dir, 'spatial_analysis')
        os.makedirs(analysis_dir, exist_ok=True)
        stats_dir = os.path.join(output_dir, 'statistics')
        os.makedirs(stats_dir, exist_ok=True)
        vis_dir = os.path.join(output_dir, 'visualizations')
        os.makedirs(vis_dir, exist_ok=True)

        # Vérifier si nous avons déjà des résultats finaux
        final_report = os.path.join(output_dir, 'rapport_explicabilite.md')
        if os.path.exists(final_report):
            print(f"Un rapport d'explicabilité existe déjà à {final_report}.")
            print("Voulez-vous le régénérer? (y/n)")
            response = input()
            if response.lower() != 'y':
                print("Utilisation du rapport existant.")
                return {
                    'output_dir': output_dir,
                    'report_path': final_report
                }

        # 1. Charger les modèles
        print("\n=== ÉTAPE 1: CHARGEMENT DES MODÈLES ===")

        print(f"Chargement du modèle de classification: {classifier_path}")
        classifier = load_size_aware_model(classifier_path, device)

        print(f"Chargement du détecteur de caractéristiques: {feature_detector_path}")
        feature_detector = FeatureDetector(feature_detector_path, device)

        # 2. Préparer le dataset
        print("\n=== ÉTAPE 2: PRÉPARATION DES DONNÉES ===")

        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        print(f"Chargement des images depuis: {img_dir}")
        dataset = MemoryEfficientDataset(img_dir, transform=transform, exclude_class=8)  # Exclure la classe FOND (8)

        if len(dataset) == 0:
            print("Aucune image trouvée dans le répertoire. Utilisation de données factices.")
            # Créer des données factices directement
            create_dummy_analysis_data(output_dir, analysis_dir)
            stats = calculate_global_stats_from_files(analysis_dir, stats_dir)
            generate_visualizations(stats, vis_dir)
            create_summary_report(stats, output_dir)
            return {'output_dir': output_dir}

        print(f"Nombre d'images dans le dataset: {len(dataset)}")

        # 3. Générer les heatmaps par lots et sauvegarder
        print("\n=== ÉTAPE 3: GÉNÉRATION DES HEATMAPS ===")
        processed_files = generate_heatmaps_in_batches(
            model=classifier,
            dataset=dataset,
            output_dir=output_dir,
            batch_size=5,  # Réduit pour éviter les problèmes de mémoire
            device=device,
            checkpoint_interval=2
        )

        # Libérer la mémoire du modèle de classification
        del classifier
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None

        # 4. Analyser les relations spatiales par lots
        print("\n=== ÉTAPE 4: ANALYSE SPATIALE ===")
        analyzed_files = analyze_spatial_relationships_in_batches(
            processed_files=processed_files,
            heatmaps_dir=heatmaps_dir,
            feature_detector=feature_detector,
            output_dir=output_dir,
            batch_size=5,  # Réduit pour éviter les problèmes de mémoire
            device=device
        )

        # Libérer la mémoire du détecteur de caractéristiques
        del feature_detector
        gc.collect()
        torch.cuda.empty_cache() if torch.cuda.is_available() else None

        # 5. Calculer les statistiques globales
        print("\n=== ÉTAPE 5: CALCUL DES STATISTIQUES ===")
        stats = calculate_global_stats_from_files(
            analysis_dir=analysis_dir,
            output_dir=stats_dir
        )

        # 6. Générer les visualisations
        print("\n=== ÉTAPE 6: GÉNÉRATION DES VISUALISATIONS ===")
        generate_visualizations(stats, vis_dir)

        # 7. Créer un rapport de synthèse
        print("\n=== ÉTAPE 7: CRÉATION DU RAPPORT ===")
        create_summary_report(stats, output_dir)

        print(f"\nAnalyse terminée. Résultats dans: {output_dir}")

        return {
            'processed_files': processed_files,
            'analyzed_files': analyzed_files,
            'output_dir': output_dir
        }

    except Exception as e:
        print(f"Erreur lors de l'analyse d'explicabilité: {e}")
        import traceback
        traceback.print_exc()

        # Écrire l'erreur dans un fichier
        with open(os.path.join(output_dir, 'error_log.txt'), 'w') as f:
            f.write(f"Erreur lors de l'analyse d'explicabilité: {e}\n")
            f.write(traceback.format_exc())

        # Tenter de générer des résultats minimaux avec des données factices
        print("Tentative de génération de résultats minimaux avec des données factices...")

        try:
            create_dummy_analysis_data(output_dir, analysis_dir)
            stats = calculate_global_stats_from_files(analysis_dir, stats_dir)
            generate_visualizations(stats, vis_dir)
            create_summary_report(stats, output_dir)
            print(f"Rapport minimal généré dans: {output_dir}")
        except Exception as e2:
            print(f"Échec de la génération de résultats minimaux: {e2}")

        return None

# Utilisation
if __name__ == "__main__":
    # Chemins des modèles et répertoires
    classifier_path = "collembole_classifier_b4_size_aware.pth"
    feature_detector_path = "faster_rcnn_antennes.pth"
    img_dir = "/content/drive/MyDrive/PROJET_COLLEMBOLE/Données challenge deep/datatest/datatest"
    output_dir = "resultats_explicabilite"

    # Utiliser CUDA si disponible
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Utilisation du dispositif: {device}")

    # Exécuter l'analyse d'explicabilité
    results = main(classifier_path, feature_detector_path, img_dir, output_dir, device)